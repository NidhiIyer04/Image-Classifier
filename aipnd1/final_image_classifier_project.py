# -*- coding: utf-8 -*-
"""Final_image_classifier_project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1AxQBd2Q16t1OqDrxIiAzH8OF8nex_GbI

## AI Programming with Python Nanodegree: Image Classifier Project
"""

# imports
# In a cell at the beginning of your Colab notebook
import sys
sys.argv = ["train.py", "data_directory", "--save_dir", "save_directory", "--arch", "vgg13", "--learning_rate", "0.01", "--hidden_units", "512", "--epochs", "20", "--gpu"]
from torchvision import datasets

import os
import requests
from pathlib import Path
import tarfile
import json
import torch
import torch
import torch.nn as nn
import torchvision
import matplotlib.pyplot as plt
import numpy as np
from torchvision import transforms
from PIL import Image

try:
    from torchinfo import summary
    from tqdm.autonotebook import tqdm
    from torchmetrics.classification import MulticlassAccuracy, MulticlassF1Score
except:
    print("[INFO] Installing torchinfo for network architecture explanation.")
#    !pip install torchinfo
    from torchinfo import summary
try:
    from tqdm.autonotebook import tqdm
    from torchmetrics.classification import MulticlassAccuracy, MulticlassF1Score
except ImportError:
    print("[INFO] Installing required libraries.")
#    !pip install tqdm torchmetrics
    from tqdm.autonotebook import tqdm
    from torchmetrics.classification import MulticlassAccuracy, MulticlassF1Score

#!pip install torchmetrics
from typing import Tuple
from torchmetrics.classification import MulticlassAccuracy, MulticlassF1Score
from typing import Callable, Any
import functools
import time
import copy
from tqdm import tqdm

# defining dataset directory
data_dir = './flowers'

# using pathlib.Path for handling PosixPath
FLOWERS_DIR = Path(data_dir)

# downloading and setting up data if not already present
if not FLOWERS_DIR.is_dir():
    # creating directory
    FLOWERS_DIR.mkdir(parents=True, exist_ok=True)
    print(f"[INFO] Directory created: ./{FLOWERS_DIR}")

    print() # for readability

    # tarball path
    TARBALL = FLOWERS_DIR / "flower_data.tar.gz"

    # downloading and writing the tarball to './flowers' directory
    print(f"[INFO] Downloading the file 'flower_data.tar.gz' to ./{FLOWERS_DIR}")
    request = requests.get('https://s3.amazonaws.com/content.udacity-data.com/nd089/flower_data.tar.gz')
    with open(TARBALL, "wb") as file_ref:
        file_ref.write(request.content)
        print(f"[INFO] 'flower_data.tar.gz' saved to ./{FLOWERS_DIR}")

    print() # for readability

    # extracting the downloaded tarball
    print(f"[INFO] Extracting the downloaded tarball to ./{FLOWERS_DIR}")
    with tarfile.open(TARBALL, "r") as tar_ref:
        tar_ref.extractall(FLOWERS_DIR)
        print(f"[INFO] 'flower_data.tar.gz' extracted successfully to ./{FLOWERS_DIR}")

    print() # for readability

    # using os.remove to delete the downloaded tarball
    print("[INFO] Deleting the tarball to save space.")
    os.remove(TARBALL)
else:
    print(f"[INFO] Dataset already setup at ./{FLOWERS_DIR}")

data = {
    "21": "fire lily", "3": "canterbury bells", "45": "bolero deep blue", "1": "pink primrose", "34": "mexican aster",
    "27": "prince of wales feathers", "7": "moon orchid", "16": "globe-flower", "25": "grape hyacinth", "26": "corn poppy",
    "79": "toad lily", "39": "siam tulip", "24": "red ginger", "67": "spring crocus", "35": "alpine sea holly",
    "32": "garden phlox", "10": "globe thistle", "6": "tiger lily", "93": "ball moss", "33": "love in the mist",
    "9": "monkshood", "102": "blackberry lily", "14": "spear thistle", "19": "balloon flower", "100": "blanket flower",
    "13": "king protea", "49": "oxeye daisy", "15": "yellow iris", "61": "cautleya spicata", "31": "carnation",
    "64": "silverbush", "68": "bearded iris", "63": "black-eyed susan", "69": "windflower", "62": "japanese anemone",
    "20": "giant white arum lily", "38": "great masterwort", "4": "sweet pea", "86": "tree mallow",
    "101": "trumpet creeper", "42": "daffodil", "22": "pincushion flower", "2": "hard-leaved pocket orchid",
    "54": "sunflower", "66": "osteospermum", "70": "tree poppy", "85": "desert-rose", "99": "bromelia", "87": "magnolia",
    "5": "english marigold", "92": "bee balm", "28": "stemless gentian", "97": "mallow", "57": "gaura",
    "40": "lenten rose", "47": "marigold", "59": "orange dahlia", "48": "buttercup", "55": "pelargonium",
    "36": "ruby-lipped cattleya", "91": "hippeastrum", "29": "artichoke", "71": "gazania", "90": "canna lily",
    "18": "peruvian lily", "98": "mexican petunia", "8": "bird of paradise", "30": "sweet william",
    "17": "purple coneflower", "52": "wild pansy", "84": "columbine", "12": "colt's foot", "11": "snapdragon",
    "96": "camellia", "23": "fritillary", "50": "common dandelion", "44": "poinsettia", "53": "primula",
    "72": "azalea", "65": "californian poppy", "80": "anthurium", "76": "morning glory", "37": "cape flower",
    "56": "bishop of llandaff", "60": "pink-yellow dahlia", "82": "clematis", "58": "geranium", "75": "thorn apple",
    "41": "barbeton daisy", "95": "bougainvillea", "43": "sword lily", "83": "hibiscus", "78": "lotus lotus",
    "88": "cyclamen", "94": "foxglove", "81": "frangipani", "74": "rose", "89": "watercress", "73": "water lily",
    "46": "wallflower", "77": "passion flower", "51": "petunia"
}

with open('cat_to_name.json', 'w') as file:
    json.dump(data, file)

def manual_seed(random_seed: int = 42) -> None:
    '''
    For maintaining reproducibility of a notebook cell.
    '''
    # Set seed for generating random numbers on the CPU
    torch.manual_seed(random_seed)

    # Set seed for generating random numbers on the GPU if available
    if torch.cuda.is_available():
        torch.cuda.manual_seed(random_seed)

# Determine the device (GPU or CPU) to be used for computation
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# Clear the GPU cache if computation is performed on the GPU
if str(device) == "cuda":
    torch.cuda.empty_cache()

BATCH_SIZE = 32
LEARNING_RATE = 2e-4
EPOCHS = 15
HIDDEN_LAYER_1 = 256
HIDDEN_LAYER_2 = 128

resnet_34_weights = torchvision.models.ResNet34_Weights.DEFAULT
resnet_34_default_transforms = resnet_34_weights.transforms()
print(resnet_34_default_transforms)
model = torchvision.models.resnet34(weights = resnet_34_weights)

summary(model,
        input_size=(1,3,224,224),
        col_names=("input_size",
                   "output_size",
                   "num_params",
                   "kernel_size",
                   "mult_adds",
                   "trainable"),
        col_width=20,
        row_settings=("var_names",))

# Training transforms with augmentations
train_transforms = transforms.Compose([
    transforms.Resize(size=(256, 256), interpolation=transforms.InterpolationMode.BILINEAR),
    transforms.TrivialAugmentWide(interpolation=transforms.InterpolationMode.BILINEAR),
    transforms.CenterCrop(size=(224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

# Validation and test transforms without augmentations
val_test_transforms = transforms.Compose([
    transforms.Resize(size=(256, 256), interpolation=transforms.InterpolationMode.BILINEAR),
    transforms.CenterCrop(size=(224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

# Training dataset
train_dataset = datasets.ImageFolder(root=str(FLOWERS_DIR / 'train'), transform=train_transforms)

# Validation dataset
val_dataset = datasets.ImageFolder(root=str(FLOWERS_DIR / 'valid'), transform=val_test_transforms)

# Test dataset
test_dataset = datasets.ImageFolder(root=str(FLOWERS_DIR / 'test'), transform=val_test_transforms)

CLASSES = train_dataset.classes
NUM_CLASSES = len(CLASSES)
CLASS_TO_IDX = train_dataset.class_to_idx

# data loaders
train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)
val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=32, shuffle=False)
test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False)

import json

# Load cat_to_name mapping from JSON file
with open('cat_to_name.json', 'r') as file:
    cat_to_name = json.load(file)

def denormalize_and_clip(img, mean, std):
    img = img.numpy(force=True) if isinstance(img, torch.Tensor) else img
    img = np.transpose(img, (1, 2, 0))
    img = std * img + mean
    img = np.clip(img, 0, 1)
    return img

def imshow(img, title):
    plt.imshow(img)
    plt.title(title)
    plt.axis('off')
    plt.show()

def visualize_random_batch(data_loader, loader_type, mean, std, cat_to_name):
    batch_index = np.random.randint(len(data_loader))
    for i, (images, labels) in enumerate(data_loader):
        if i == batch_index:
            break

    classes = data_loader.dataset.classes
    num_images_to_show = min(5, len(images))
    fig, axes = plt.subplots(1, num_images_to_show, figsize=(15, 3))

    for i in range(num_images_to_show):
        image = images[i]
        label = labels[i].item()
        class_name = classes[label]

        image = denormalize_and_clip(image, mean, std)
        axes[i].imshow(image)
        axes[i].set_title(f'Class: {class_name} - {cat_to_name[str(label)]}')
        axes[i].axis('off')

    plt.suptitle(f'{loader_type} Random Batch')
    plt.show()

mean = np.array([0.485, 0.456, 0.406])
std = np.array([0.229, 0.224, 0.225])

# Assuming train_loader and val_loader are defined
# Also, create IDX_TO_CLASS based on cat_to_name
IDX_TO_CLASS = {v: k for k, v in cat_to_name.items()}

# Replace 'train_loader' and 'val_loader' with your actual data loaders
visualize_random_batch(train_loader, 'Train Loader', mean, std, cat_to_name)
visualize_random_batch(val_loader, 'Validation Loader', mean, std, cat_to_name)

manual_seed()
for param in model.parameters():
    param.requires_grad = False
model.fc = nn.Sequential(nn.Linear(512, HIDDEN_LAYER_1),
                         nn.ReLU(),
                         nn.Dropout(p=0.2),
                         nn.Linear(HIDDEN_LAYER_1, HIDDEN_LAYER_2),
                         nn.ReLU(),
                         nn.Dropout(p=0.2),
                         nn.Linear(HIDDEN_LAYER_2, len(train_dataset.classes)))

summary(model,
        input_size=(1,3,224,224),
        col_names=("input_size",
                   "output_size",
                   "num_params",
                   "kernel_size",
                   "mult_adds",
                   "trainable"),
        col_width=20,
        row_settings=("var_names",))

def training_step(model: nn.Module,
                  train_dataloader: torch.utils.data.DataLoader,
                  optimizer: torch.optim.Optimizer,
                  criterion: nn.Module,
                  training_accuracy: MulticlassAccuracy,
                  training_f1: MulticlassF1Score,
                  epoch_num: int,
                  device: torch.device = device) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:
    model.train()
    epoch_loss = 0
    with tqdm(enumerate(train_dataloader, start=1), total=len(train_dataloader), unit=" train-batch") as tepoch:
        for batch_idx, (features, labels) in tepoch:
            tepoch.set_description(f"Epoch: {epoch_num+1} | Phase - Training")

            features, labels = features.to(device), labels.to(device).type(torch.long)
            logits = model(features)
            loss = criterion(logits, labels)
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            with torch.inference_mode():
                avg_loss_sample = loss/len(labels)
                batch_acc = training_accuracy.forward(logits, labels)
                batch_f1 = training_f1.forward(logits, labels)
            epoch_loss += avg_loss_sample
            tepoch.set_postfix(batch_f1_score=batch_f1.item(), batch_accuracy=f"{batch_acc.item()*100:.2f}%", loss_per_sample=avg_loss_sample.item())
    epoch_loss /= len(train_dataloader)
    print()
    print(f"[INFO] Epoch: {epoch_num+1} | loss: {epoch_loss.item():.3f} | training acc: {training_accuracy.compute().item()*100:.2f}% | training f1-score: {training_f1.compute().item():.2f}")
    return epoch_loss, training_accuracy.compute(), training_f1.compute()

def testing_step(model: nn.Module,
                 test_dataloader: torch.utils.data.DataLoader,
                 criterion: nn.Module,
                 test_accuracy: MulticlassAccuracy,
                 test_f1: MulticlassF1Score,
                 epoch_num: int = -1,
                 device: torch.device = device) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:
    model.eval()
    epoch_loss = 0
    with tqdm(enumerate(test_dataloader, start=1), total=len(test_dataloader), unit=" test-batch") as tepoch:
        for batch_idx, (features, labels) in tepoch:
            tepoch.set_description(f"Epoch: {epoch_num+1} | Phase - Validation/Test")
            features, labels = features.to(device), labels.to(device).type(torch.long)
            with torch.inference_mode():
                logits = model(features)
                loss = criterion(logits, labels)
                avg_loss_sample = loss/len(labels)
                batch_acc = test_accuracy.forward(logits, labels)
                batch_f1 = test_f1.forward(logits, labels)
            epoch_loss += avg_loss_sample
            tepoch.set_postfix(batch_f1_score=batch_f1.item(), batch_accuracy=f"{batch_acc.item()*100:.2f}%", loss_per_sample=avg_loss_sample.item())
    epoch_loss /= len(test_dataloader)
    print()
    print(f"[INFO] Epoch: {epoch_num+1} | loss: {epoch_loss.item():.3f} | val/test acc: {test_accuracy.compute().item()*100:.2f}% | val/test f1-score: {test_f1.compute().item():.2f}")
    print()
    return epoch_loss, test_accuracy.compute(), test_f1.compute()

def timing_function(func: Callable[..., Any]) -> Callable[..., Any]:
    @functools.wraps(func)
    def wrapper(*args, **kwargs) -> Any:
        start_time = time.perf_counter()
        func_out = func(*args, **kwargs)
        end_time = time.perf_counter()
        print()
        print()
        print(f"[INFO] Time taken -> {(end_time-start_time)//60}m and {(end_time-start_time)%60:.2f}s")
        return func_out
    return wrapper

@timing_function
def training(model: nn.Module,
             train_dataloader: torch.utils.data.DataLoader,
             test_dataloader: torch.utils.data.DataLoader,
             optimizer: torch.optim.Optimizer,
             criterion: nn.Module,
             training_accuracy: MulticlassAccuracy,
             training_f1: MulticlassF1Score,
             test_accuracy: MulticlassAccuracy,
             test_f1: MulticlassF1Score,
             epochs: int = 5,
             device: torch.device = device) -> Tuple[dict, dict]:
             model.to(device)
             training_accuracy.to(device)
             training_f1.to(device)
             test_accuracy.to(device)
             test_f1.to(device)
             train_loss = []
             train_acc = []
             train_f1 = []
             val_loss = []
             val_acc = []
             val_f1 = []
             best_loss = float("inf")
             for epoch_iter in range(epochs):
                train_epoch_loss, train_epoch_acc, train_epoch_f1 = training_step(model,
                                                                                  train_dataloader,
                                                                                  optimizer,
                                                                                  criterion,
                                                                                  training_accuracy,
                                                                                  training_f1,
                                                                                  epoch_iter,
                                                                                  device)
                train_loss.append(train_epoch_loss)
                train_acc.append(train_epoch_acc)
                train_f1.append(train_epoch_f1)
                print()
                val_epoch_loss, val_epoch_acc, val_epoch_f1 = testing_step(model,
                                                                           test_dataloader,
                                                                           criterion,
                                                                           test_accuracy,
                                                                           test_f1,
                                                                           epoch_iter,
                                                                           device)
                val_loss.append(val_epoch_loss)
                val_acc.append(val_epoch_acc)
                val_f1.append(val_epoch_f1)
                print()
                if best_loss > val_epoch_loss:
                    best_model = copy.deepcopy(model.state_dict())
                    best_loss = val_epoch_loss
                    best_epoch = epoch_iter
             train_loss = [tensor.item() for tensor in train_loss]
             train_acc = [tensor.item() for tensor in train_acc]
             train_f1 = [tensor.item() for tensor in train_f1]
             val_loss = [tensor.item() for tensor in val_loss]
             val_acc = [tensor.item() for tensor in val_acc]
             val_f1 = [tensor.item() for tensor in val_f1]
             training_statistics = {"training_loss": train_loss,
                                    "training_accuracy": train_acc,
                                    "training_f1": train_f1,
                                    "validation_loss": val_loss,
                                    "validation_accuracy": val_acc,
                                    "validation_f1": val_f1,
                                    "best_epoch": best_epoch+1,
                                    "loss_on_best_epoch": best_loss.item(),
                                    "device_used": device}
             print()
             print()
             print(f"Best epoch: {training_statistics['best_epoch']} | Training acc on best epoch: {training_statistics['training_accuracy'][training_statistics['best_epoch']-1]*100:.2f}% | Validation acc on best epoch: {training_statistics['validation_accuracy'][training_statistics['best_epoch']-1]*100:.2f}%")
             return best_model, training_statistics

def save_model(model: nn.Module,
               model_name: str) -> str:
    SAVE_PATH = f"./{model_name}.pt"
    torch.save(model.state_dict(), SAVE_PATH)
    print(f"[INFO] {model_name} saved to {SAVE_PATH}")
    return SAVE_PATH
def save_checkpoint(optimizer: torch.optim.Optimizer,
                    criterion: nn.Module,
                    epoch: int,
                    device_trained_on: torch.device,
                    hidden_layers: tuple,
                    output_layer: int,
                    classes: list,
                    class_to_idx: dict,
                    checkpoint_name: str = "checkpoint") -> str:
    SAVE_PATH = f"./{checkpoint_name}.pth"
    torch.save({"optimizer": optimizer.state_dict(),
                "criterion": criterion,
                "epoch": epoch,
                "device_trained_on": device_trained_on,
                "hidden_layers": hidden_layers,
                "output_layer": output_layer,
                "classes": classes,
                "class_to_idx": class_to_idx}, SAVE_PATH)
    print(f"[INFO] The general checkpoint has been saved to: {SAVE_PATH}")
    return SAVE_PATH
def load_model(model_save_path: str,
               hidden_layers: tuple,
               output_layer: int,
               device_trained_on: torch.device,
               device: torch.device) -> nn.Module:
    model = torchvision.models.resnet34(weights = None)
    model.fc = nn.Sequential(nn.Linear(512, hidden_layers[0]),
                             nn.ReLU(),
                             nn.Dropout(p=0.2),
                             nn.Linear(hidden_layers[0], hidden_layers[1]),
                             nn.ReLU(),
                             nn.Dropout(p=0.2),
                             nn.Linear(hidden_layers[1], output_layer))
    if str(device_trained_on) in ("cuda", "cuda:0"):
        if str(device) == "cpu":
            model.load_state_dict(torch.load(model_save_path, map_location=device))
        elif str(device) in ("cuda", "cuda:0"):
            model.load_state_dict(torch.load(model_save_path))
    else:
        if str(device) == "cpu":
            model.load_state_dict(torch.load(model_save_path))
        elif str(device) in ("cuda", "cuda:0"):
            model.load_state_dict(torch.load(model_save_path, map_location="cuda:0"))
    model.to(device);
    model.eval();
    return model
def load_checkpoint(checkpoint_save_path: str) -> dict:
    CHECKPOINT_DICT = torch.load(checkpoint_save_path)
    return CHECKPOINT_DICT

criterion = nn.CrossEntropyLoss()

optimizer = torch.optim.AdamW(model.fc.parameters(),
                             lr = LEARNING_RATE)
training_acc = MulticlassAccuracy(num_classes = NUM_CLASSES)
training_f1 = MulticlassF1Score(num_classes = NUM_CLASSES)
val_acc = MulticlassAccuracy(num_classes = NUM_CLASSES)
val_f1 = MulticlassF1Score(num_classes = NUM_CLASSES)

manual_seed()


resnet_state_dict, training_stats = training(model,
                                             train_dataloader = train_loader,
                                             test_dataloader = val_loader,
                                             optimizer = optimizer,
                                             criterion = criterion,
                                             training_accuracy = training_acc,
                                             training_f1 = training_f1,
                                             test_accuracy = val_acc,
                                             test_f1 = val_f1,
                                             epochs=EPOCHS)

def plot_training_curves(stats):
    training_loss = stats['training_loss']
    training_accuracy = stats['training_accuracy']
    training_f1 = stats['training_f1']
    validation_loss = stats['validation_loss']
    validation_accuracy = stats['validation_accuracy']
    validation_f1 = stats['validation_f1']
    best_epoch = stats['best_epoch']
    loss_on_best_epoch = stats['loss_on_best_epoch']
    epochs = range(1, len(training_loss) + 1)

    plt.figure(figsize=(15, 5))

    # Plot of Training Loss and Validation Loss
    plt.subplot(1, 3, 1)
    plt.plot(epochs, training_loss, label='Training Loss')
    plt.plot(epochs, validation_loss, label='Validation Loss')
    plt.scatter(best_epoch, loss_on_best_epoch, color='darkred', marker='o', label='Best Epoch')
    plt.title('Loss Curves')
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.xticks(epochs)
    plt.legend()

    # Plot of Training Accuracy and Validation Accuracy
    plt.subplot(1, 3, 2)
    plt.plot(epochs, training_accuracy, label='Training Accuracy')
    plt.plot(epochs, validation_accuracy, label='Validation Accuracy')
    plt.title('Accuracy Curves')
    plt.xlabel('Epochs')
    plt.ylabel('Accuracy')
    plt.xticks(epochs)
    plt.legend()

    # Plot Training F1-score and Validation F1-score
    plt.subplot(1, 3, 3)
    plt.plot(epochs, training_f1, label='Training F1-score')
    plt.plot(epochs, validation_f1, label='Validation F1-score')
    plt.title('F1-score Curves')
    plt.xlabel('Epochs')
    plt.ylabel('F1-score')
    plt.xticks(epochs)
    plt.legend()

    plt.tight_layout()
    plt.show()

MODEL_SAVE_PATH = save_model(model, "resnet_34")
CHKPT_SAVE_PATH = save_checkpoint(optimizer,
                                  criterion,
                                  epoch = training_stats["best_epoch"]-1,
                                  device_trained_on = device,
                                  hidden_layers = (HIDDEN_LAYER_1, HIDDEN_LAYER_2),
                                  output_layer = NUM_CLASSES,
                                  classes = CLASSES,
                                  class_to_idx = CLASS_TO_IDX,
                                  checkpoint_name = "checkpoint")
CHKPT_DICT = load_checkpoint(CHKPT_SAVE_PATH)

loaded_model = load_model(MODEL_SAVE_PATH,
                          hidden_layers=(HIDDEN_LAYER_1, HIDDEN_LAYER_2),
                          output_layer=102,
                          device_trained_on=device,
                          device=device)

def evaluate_model(model, dataloader, criterion, device):
    model.eval()
    total_correct = 0
    total_samples = 0
    total_loss = 0.0

    with torch.inference_mode():
        with tqdm(enumerate(dataloader, start=1), total=len(dataloader), unit=" test-batch") as tepoch:
            for batch_idx, (features, labels) in tepoch:
                tepoch.set_description("Evaluating")

                features, labels = features.to(device), labels.to(device).type(torch.long)
                logits = model(features)
                loss = criterion(logits, labels)
                total_loss += loss.item()

                predictions = torch.argmax(logits, dim=1)
                total_correct += torch.sum(predictions == labels)
                total_samples += labels.size(0)

                tepoch.set_postfix(loss_per_sample=loss.item())

    accuracy = total_correct / total_samples
    average_loss = total_loss / len(dataloader)

    return accuracy, average_loss

test_accuracy, test_loss = evaluate_model(loaded_model, test_loader, criterion, device)

print(f"Test Accuracy: {test_accuracy.item()*100:.2f}%")
print(f"Test Loss: {test_loss:.3f}")

device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
loaded_model.to(device)

CHECKPOINT_DICT = load_checkpoint("checkpoint.pth")
class_to_idx = CHECKPOINT_DICT.get("class_to_idx", {})

# idx_to_class mapping
idx_to_class = {v: k for k, v in class_to_idx.items()}


# class_to_name dictionary
class_to_name = {str(k): v for k, v in cat_to_name.items()}

@timing_function
def predict_and_plot_topk(model: nn.Module,
                          img_transform: transforms.Compose,
                          idx_to_class: dict,
                          image_path: str,
                          device: torch.device,
                          class_to_name: dict,
                          topk: int = 5):
    image = Image.open(image_path).convert("RGB")
    input_tensor = img_transform(image)
    input_batch = input_tensor.unsqueeze(0).to(device)
    input_batch = input_batch.to(device)
    model.to(device)

    with torch.inference_mode():
        output = model(input_batch)

    probabilities = torch.nn.functional.softmax(output[0], dim=0)

    topk_probs, topk_indices = torch.topk(probabilities, topk)
    topk_probs_np = topk_probs.cpu().numpy()
    topk_indices_np = topk_indices.cpu().numpy()
    top_classes = [class_to_name[idx_to_class[idx]] for idx in topk_indices_np]

    plt.figure(figsize=(10, 6))
    plt.subplot(2, 1, 1)
    plt.imshow(image)
    plt.title('Input Image')
    plt.axis('off')
    plt.subplot(2, 1, 2)
    plt.barh(top_classes, topk_probs_np, color='blue')
    plt.xlabel('Predicted Probability')
    plt.title(f'Top-{topk} Predicted Classes')
    plt.tight_layout()
    plt.show()
#Ex
#!wget https://upload.wikimedia.org/wikipedia/commons/f/fd/Pink_flower.jpg -O image.jpg
predict_and_plot_topk(loaded_model, resnet_34_default_transforms, idx_to_class, "image.jpg", device, class_to_name, topk=5)

#!jupyter nbconvert --to html "/content/Final_image_classifier_project (2).ipynb"
